# ğŸš€ Machine Learning Model Deployment Using Docker ğŸ³ğŸ¤–  

![Docker](https://img.shields.io/badge/Docker-âœ”ï¸-blue)  
![Python](https://img.shields.io/badge/Python-3.9-blue)  
![Streamlit](https://img.shields.io/badge/Streamlit-âœ”ï¸-red)  
![AWS EC2](https://img.shields.io/badge/AWS%20EC2-âœ”ï¸-orange)  
![License](https://img.shields.io/badge/License-MIT-green)  

## ğŸ“Œ Project Overview  

This project demonstrates how to **containerize an ML model** using **Docker** and deploy it as a **Streamlit web application**. The model is trained on the `mushrooms.csv` dataset and allows users to interact with the predictions in real-time.  

By the end of this tutorial, you'll have a **fully functional ML model** running inside a **Docker container**, ready for **inference or further development**. ğŸš€  

---

## ğŸ—ï¸ Features  

âœ… **Machine Learning Model** trained on the `mushrooms.csv` dataset  
âœ… **Streamlit-based Web App** for interactive user experience  
âœ… **Dockerized for Portability** â€“ Run anywhere, independent of system dependencies  
âœ… **AWS EC2 Deployment** for **scalability & accessibility**  
âœ… **Real-time Predictions & Visualizations**  

---

## ğŸ“‚ Project Structure  

/ml-docker-app  
â”‚â”€â”€ app.py # Streamlit application with ML model  
â”‚â”€â”€ mushrooms.csv # Dataset used for training  
â”‚â”€â”€ requirements.txt # Python dependencies  
â”‚â”€â”€ Dockerfile # Instructions for building the Docker image  
â”‚â”€â”€ README.md # Project documentation

---

## ğŸš€ Prerequisites  

Before starting, ensure you have the following installed:  

- **[Docker](https://docs.docker.com/get-docker/)** ğŸ³  
- **[Python 3.9+](https://www.python.org/downloads/)** ğŸ  
- **[Streamlit](https://docs.streamlit.io/)**  
- **AWS EC2 Instance** (for cloud deployment)  

---

## ğŸ”§ Installation & Setup  

### Step 1ï¸âƒ£: Clone the Repository  

```bash
git clone https://github.com/your-username/ml-docker-app.git
cd ml-docker-app
```
Step 2ï¸âƒ£: Install Dependencies
```bash
pip install -r requirements.txt
```
Step 3ï¸âƒ£: Run the App Locally
```bash
streamlit run app.py
```
**ğŸ³ Dockerizing the Application**  

Step 1ï¸âƒ£: Build the Docker Image
```bash
docker build -t ml-model .
```
Step 2ï¸âƒ£: Run the Docker Container
```bash
docker run -p 8501:8501 ml-model
```
Step 3ï¸âƒ£: Access the App
Open your browser and go to:
ğŸ‘‰ http://localhost:8501

**ğŸš€ Deploying on AWS EC2 ğŸŒ**  

Step 1ï¸âƒ£: Set Up Your AWS EC2 Instance  

Log in to AWS & navigate to EC2 Dashboard.  

Launch an instance with Amazon Linux 2 AMI.  

Select instance type t2.micro (free tier).  

Configure security groups to allow SSH (port 22) and HTTP (port 8501).  

Launch the instance and download the key pair (.pem file).  


Step 2ï¸âƒ£: Connect to EC2 via SSH
```bash
ssh -i /path/to/your-key.pem ec2-user@your-ec2-public-ip
```
Step 3ï¸âƒ£: Install Docker on EC2
```bash
sudo yum update -y
sudo yum install docker -y
sudo service docker start
sudo usermod -a -G docker ec2-user
```
Step 4ï¸âƒ£: Deploy the Streamlit App
```bash
git clone https://github.com/your-username/ml-docker-app.git
cd ml-docker-app
docker build -t streamlit-app .
docker run -d -p 8501:8501 --name my-streamlit-app streamlit-app
```
Step 5ï¸âƒ£: Access the App
ğŸ‘‰ Open your browser and go to:
http://your-ec2-public-ip:8501

âš¡ Automate Deployment (Optional)
Ensure the app runs automatically after system reboot:

```bash
sudo docker update --restart unless-stopped my-streamlit-app
```

**ğŸ‰ Conclusion**
Congratulations! ğŸ‰ You have successfully:  


âœ… Trained an ML model   

âœ… Created an interactive web app with Streamlit  

âœ… Containerized the app using Docker  

âœ… Deployed the app on AWS EC2  
